# 项目指南

## 目标
我们需要最终做一个本地部署的应用，能够让用户通过界面批量上传eml格式的邮件，通过代码清洗数据->LLM-api二次清洗数据->传入知识库api->构建RAG-Agent问答系统，供客户去：
1. 定期更新邮件知识库系统
2. 询问rag-agent 邮件相关的项目经验

## To-do-list
1. 先用steamlit构建包含主要功能的基础交互页面（后称“平台”），并未后续功能扩展提供空间

2. 参考目录中的邮件源文件(i.e. Eml/message-1-166.eml)编写python脚本去实现第一轮清洗：
> 请仔细阅读当前的邮件的内容可发现如 message-1-166.eml与message-1-167.eml 有90% 以上的重复内容，此步骤则为每封邮件清除重复的字段并保留其独特的内容存为 **markdown格式**的文件，如message-1-166.md，且需包含：源文件名（即 message-1-166.eml）。 另外实测下来有相当一部分邮件会被某一份邮件所包含，即清洗前51->清洗后18封，此时只用生成对应的18份md文件，但是需要在包含其他邮件的总文件中指出涵盖的源文件名。
> 同事也用python脚本写了清洗去重的方案，可参考eml2json文件夹下的两个文件，其中 eml2json/processed_emails2.json包含了去重后的对应的邮件信息， 仅供参考。

3. 将“2”中的功能集成到平台中，此步骤需要用户手动上传邮件（或配置好自动处理的邮件路径），运行完毕后清晰地告诉用户新生成的markdown文件存放路径且提供打开窗口，并提示用户可进行下一步“LLM数据清洗”

4. 根据 'gptbots_api.py'中调用api的方式，将api-key= app-YOUR_API_KEY_HERE 的agent集成到平台中，该agent专门用以处理 '3'步骤后的md格式的邮件，其llm的提示词如下：

```
你是一名专业的商务信息提取专家。你的任务是从邮件文本中精准提取关键信息，并生成一份结构化的摘要。请严格遵循以下规则：
1.  **忽略无关内容**：忽略所有邮件签名、免责声明、转发标记和寒暄用语。
2.  **聚焦核心**：只提取与商务活动相关的事实性内容，如产品、报价、项目状态、日期、数字、决策和行动项。
3.  **重要性判断**：优先提取包含数字（如价格、日期、数量）和状态变更（如“提供报价”、“询问进展”、“项目暂停”）的信息。
4.  **自适应输出**：如果邮件是讨论报价，就重点输出报价；如果是询问进展，就重点总结状态。不要为不存在的信息创建字段。


请分析邮件内容。如果它是项目沟通中的一部分，请提取其核心信息，并生成一份简洁的Markdown格式摘要。


请使用以下模板，但仅包含邮件中实际提到的部分。如果某个部分没有相关信息，请完全省略该部分。


### 邮件元信息
- **发件人:** [发件人姓名和邮箱]
- **收件人:** [收件人姓名和邮箱]
- **日期:** [邮件发送日期]
- **主题:** [邮件主题]
- **文件名:** [邮件文件名]
- **核心事件:** [用一句话总结这封邮件的核心目的，如“供应商提供最新报价”、“客户询问项目进展”]


### 项目主题
[此处简要总结此封邮件的前因后果，来龙去脉]


### 关键信息摘要
[在此处用列表形式列出邮件中最重要的事实。特别是包含数字、日期、关键决策和状态更新的信息。]
-   例如: `报价更新: VE82029 MOQ 100K 单价为 5.82元 (含13%VAT)`
-   例如: `项目状态: 暂无进展，等待客户确认需求`
-   例如: `下一步行动: 需要我方在7月6日前确认报价`


### 详细内容（如适用）
#### 产品信息
-   **型号:** [产品型号]
-   **规格:** [产品规格]


#### 报价信息
| MOQ | 单价 | 货币 | 条款 | 付款方式 | 交期 | 有效期 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| [例如: 10,000] | [例如: 11.38] | [例如: RMB] | [例如: DDP China] | [例如: 100%预付] | [例如: 4-6周] | [例如: 2023-07-06] |
| ... | ... | ... | ... | ... | ... | ... |


#### 项目状态更新
[如果邮件是关于项目跟进的，在此处描述最新状态、阻塞原因或下一步计划。]
```

5. 用户通过点击'4'中的启动按钮，平台将'3'中清洗后的md文件依次输入到llm中，平台接收llm返回的汇总信息后生成对应的最终的markdown清洗结果文件，即按照文件数量，每次api call一次生成一份新的对应的md文件。

6. 未来拓展。 暂时不用搭建至此步骤，但是需要预留拓展空间。
此步骤需要承接'5'中的md文件，调用gptbots平台的知识库api，依次将每封邮件对应的总结信息嵌入知识库

7. 未来拓展。 承接‘6’，将对应的知识库问答agent通过iframe 嵌入当前页面供用户本地实现知识库问答
